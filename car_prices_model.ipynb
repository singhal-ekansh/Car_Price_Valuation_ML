{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "car_prices_model.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HI37JrX0NOfE"
      },
      "source": [
        "**Importing libraries**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tX_Rj7Q-NU4f"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.model_selection import RandomizedSearchCV"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tjPHLlmqNnnZ"
      },
      "source": [
        "**open csv file and seprate features and lables**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d6nc4C94NsVk"
      },
      "source": [
        "df= pd.read_csv(\"/content/Car details v3.csv\")\n",
        "\n",
        "# from rows whose mileage in km/kg \n",
        "for i in range(len(df)):\n",
        "  if str(df.loc[i,'mileage']).endswith(\"km/kg\"):\n",
        "    df.loc[i,'mileage']=np.nan\n",
        "    \n",
        "df = df.dropna()\n",
        "\n",
        "df['year']=2021-df['year']\n",
        "\n",
        "df['name'] = df['name'].str.strip()\n",
        "\n",
        "df['mileage'] = df['mileage'].str.slice(0, -5)\n",
        "df['mileage'] = df['mileage'].str.strip()\n",
        "\n",
        "df['engine'] = df['engine'].str.slice(0, -2)\n",
        "df['engine'] = df['engine'].str.strip()\n",
        "\n",
        "df['max_power'] = df['max_power'].str.slice(0, -3)\n",
        "df['max_power'] = df['max_power'].str.strip()\n",
        "\n",
        "df['max_power']=pd.to_numeric(df['max_power'])\n",
        "df['engine']= pd.to_numeric(df['engine'])\n",
        "df['mileage'] = pd.to_numeric(df['mileage'])\n",
        "\n",
        "X= df.iloc[:,[1,3,4,5,6,7,8,9,10,12]].values\n",
        "Y= df.iloc[:,2].values\n",
        "Y = Y.reshape(-1,1)\n"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vgi-7eO_N2pu"
      },
      "source": [
        "**Dealing with empty values**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5SkmWLs6N9Lq"
      },
      "source": [
        "#As we already removed rows with empty values so no need for this\n",
        "#imputer = SimpleImputer(missing_values=np.nan, strategy = 'most_frequent')\n",
        "#X = imputer.fit_transform(X)\n",
        "#Y = imputer.fit_transform(Y)"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aQnz7fquOCEJ"
      },
      "source": [
        "**perform encoding ie to convert all to numerical datas**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zMHZy-I5OIUG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b1421978-da2e-4705-c018-17a79519b98b"
      },
      "source": [
        "le2 = LabelEncoder()\n",
        "X[:,2] =  le2.fit_transform(X[:,2])\n",
        "le3 = LabelEncoder()\n",
        "X[:,3] =  le3.fit_transform(X[:,3])\n",
        "le4 = LabelEncoder()\n",
        "X[:,4] =  le4.fit_transform(X[:,4])\n",
        "le5 = LabelEncoder()\n",
        "X[:,5] =  le5.fit_transform(X[:,5])\n",
        "\n",
        "print(X[0,:])"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[7 145500 0 1 1 0 23.4 1248 74.0 5.0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GOFOr3rzOMHa"
      },
      "source": [
        "**feature scaling**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nL5JCLWTOQo_"
      },
      "source": [
        "#sc= StandardScaler()\n",
        "#X = sc.fit_transform(X)\n",
        "#Y = sc.fit_transform(Y)"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GMOoARyVOUE_"
      },
      "source": [
        "**splitting test and train data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SpyjREUDOXr_"
      },
      "source": [
        "X_train , X_test , Y_train , Y_test = train_test_split(X,Y,test_size=0.2,random_state = 0)"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6_8qdOo2Oaxo"
      },
      "source": [
        "**training model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nJpx_w0cOeJ0"
      },
      "source": [
        "randForestReg = RandomForestRegressor()\n",
        "### selecting parameters\n",
        "n_estimators = [int(x) for x in np.linspace(start=100 , stop = 1200 , num = 12)]\n",
        "max_features = ['auto','sqrt']\n",
        "max_depth = [int(x) for x in np.linspace(5,30,num = 6)]\n",
        "min_samples_split = [2,5,10,15,100]\n",
        "min_samples_leaf = [1,2,5,10]\n",
        "\n",
        "random_grid = {'n_estimators': n_estimators ,'max_features': max_features , 'max_depth': max_depth ,'min_samples_split' : min_samples_split,\n",
        "              'min_samples_leaf': min_samples_leaf }\n",
        "\n",
        "rf_random = RandomizedSearchCV(estimator = randForestReg , param_distributions = random_grid , scoring = 'neg_mean_squared_error',\n",
        "                               n_iter = 10,cv=5,random_state = 42 , n_jobs = 1)\n",
        "\n",
        "rf_random.fit(X_train,Y_train.ravel())\n",
        "\n",
        "y_predicted = rf_random.predict(X_test)\n",
        "\n",
        "y_predicted = y_predicted.reshape(-1,1)\n"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BtPYIrZLOoAt"
      },
      "source": [
        "**analyse model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NjP6-3iNOrBs",
        "outputId": "dbebeca3-4854-456f-ea02-0e0e4fa57537"
      },
      "source": [
        "#print((y_predicted))\n",
        "#print((Y_test))\n",
        "  \n",
        "print(mean_absolute_error((Y_test),(y_predicted)))"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "70626.29506957968\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n1IJ_GL9vAiz"
      },
      "source": [
        "**importing model to pickle file**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nuwrCHY_5JsB"
      },
      "source": [
        "import pickle\n",
        "\n",
        "file = open('/car_price_model.pkl','wb')\n",
        "\n",
        "pickle.dump(rf_random,file)\n"
      ],
      "execution_count": 41,
      "outputs": []
    }
  ]
}